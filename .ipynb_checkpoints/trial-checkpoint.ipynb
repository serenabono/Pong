{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import plotly\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "import plotly.express as px\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_trial_learnability_BoltzmannAgent_Boltzmann_pong_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0.5}', '_trial_learnability_BoltzmannAgent_Boltzmann_pong_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0.1}', '_trial_generalization_BoltzmannAgent_Boltzmann_pong_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0}', '_trial_learnability_BoltzmannAgent_Boltzmann_pong_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0}']\n",
      "_trial_learnability_BoltzmannAgent_Boltzmann_pong_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0.5}\n",
      "_trial_learnability_BoltzmannAgent_Boltzmann_pong_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0.1}\n",
      "_trial_generalization_BoltzmannAgent_Boltzmann_pong_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0}\n",
      "_trial_learnability_BoltzmannAgent_Boltzmann_pong_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import csv \n",
    "\n",
    "data = {}\n",
    "name = {}\n",
    "filename = 'BoltzmannAgent_Boltzmann_pong_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}'\n",
    "paths = glob.glob(f'_trial_*{filename}*')\n",
    "print(paths)\n",
    "for path in paths:\n",
    "    print(path)\n",
    "    agent = path.split(\"_\")[-6]\n",
    "    exploration_strategy = path.split(\"_\")[-5]\n",
    "    grid = path.split(\"_\")[-4]\n",
    "    bar = \"_\".join(path.split(\"_\")[-3:-1])\n",
    "    noise = \"\".join(path.split(\"_\")[-1])\n",
    "    pkl_files = glob.glob(os.path.join(path, '*.pkl'))\n",
    "    for file in pkl_files:        \n",
    "        if \"learnability\" in path:\n",
    "            otherbar = bar\n",
    "            othernoise = noise\n",
    "        else:\n",
    "            repeat_grid = file.split(\"_\")[3]\n",
    "            path_file = f\"_{repeat_grid}\" + re.findall(r'-test.*?_end', file)[0]\n",
    "            path_file = path_file.replace(\"'\",\"\\\"\").replace(\" \", \"\").replace(\"-train\",\"\").replace(\"-test\",\"\").replace(\"_end\", \"\")\n",
    "            otherbar = \"_\".join(path_file.split(\"_\")[2:4])\n",
    "            othernoise = path_file.split(\"_\")[4]\n",
    "            \n",
    "        if agent not in data:\n",
    "            data[agent] = {}\n",
    "            name[agent] = {}\n",
    "        if exploration_strategy not in data[agent]:\n",
    "            data[agent][exploration_strategy] = {}\n",
    "            name[agent][exploration_strategy] = {}\n",
    "        if grid not in data[agent][exploration_strategy]:\n",
    "            data[agent][exploration_strategy][grid] = {}\n",
    "            name[agent][exploration_strategy][grid] = {}\n",
    "        if bar not in data[agent][exploration_strategy][grid]:\n",
    "            data[agent][exploration_strategy][grid][bar] = {}\n",
    "            name[agent][exploration_strategy][grid][bar] = {}\n",
    "        if noise not in data[agent][exploration_strategy][grid][bar]:\n",
    "            data[agent][exploration_strategy][grid][bar][noise] = {}\n",
    "            name[agent][exploration_strategy][grid][bar][noise] = {}\n",
    "        if otherbar not in data[agent][exploration_strategy][grid][bar][noise]:\n",
    "            data[agent][exploration_strategy][grid][bar][noise][otherbar] = {}\n",
    "            name[agent][exploration_strategy][grid][bar][noise][otherbar] = {}\n",
    "        if othernoise not in data[agent][exploration_strategy][grid][bar][noise][otherbar]:\n",
    "            name[agent][exploration_strategy][grid][bar][noise][otherbar][othernoise] = []\n",
    "            data[agent][exploration_strategy][grid][bar][noise][otherbar][othernoise] = {}\n",
    "            data[agent][exploration_strategy][grid][bar][noise][otherbar][othernoise][\"tables\"] = []\n",
    "    \n",
    "        values = []\n",
    "        with open(file, newline='') as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter='\\n', quotechar='|')\n",
    "            for row in reader:\n",
    "                values.append(float(row[0]))\n",
    "        data[agent][exploration_strategy][grid][bar][noise][otherbar][othernoise][\"values\"] = values\n",
    "    \n",
    "        json_files = glob.glob(os.path.join(path, '*.json'))\n",
    "        \n",
    "        for file in json_files:\n",
    "            with open(file) as f:\n",
    "                train_epoch = file.split(\"-\")[-1].replace(rf\"train0_\",\"\").replace(\".json\",\"\")\n",
    "                data[agent][exploration_strategy][grid][bar][noise][otherbar][othernoise][\"tables\"].append(json.load(f))\n",
    "                name[agent][exploration_strategy][grid][bar][noise][otherbar][othernoise].append(f'{re.sub(\"./_trial_\", \"\", path)}_{train_epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import imageio\n",
    "\n",
    "def generate_occupancy(folder,subfolder,agent, exploration_strategy, somegrid, somebar, somenoise, someotherbar, someothernoise, sortex_idx):\n",
    "    \n",
    "    states_distribution = {}\n",
    "    if agent not in states_distribution:\n",
    "        states_distribution[agent] = {}\n",
    "    if exploration_strategy not in states_distribution[agent]:\n",
    "        states_distribution[agent][exploration_strategy] = {}\n",
    "    if somegrid not in states_distribution[agent][exploration_strategy]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid] = {}\n",
    "    if somebar not in states_distribution[agent][exploration_strategy][somegrid]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid][somebar] = {}\n",
    "    if somenoise not in states_distribution[agent][exploration_strategy][somegrid][somebar]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid][somebar][somenoise] = {}\n",
    "    if someotherbar not in states_distribution[agent][exploration_strategy][somegrid][somebar][somenoise]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid][somebar][somenoise][someotherbar] = {}\n",
    "    if someothernoise not in states_distribution[agent][exploration_strategy][somegrid][somebar][somenoise][someotherbar]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid][somebar][somenoise][someotherbar][someothernoise] = {}\n",
    "        \n",
    "    idxs = sorted(range(len(name[agent][exploration_strategy][somegrid][somebar][somenoise][somebar][somenoise])), key=lambda x: int(name[agent][exploration_strategy][somegrid][somebar][somenoise][somebar][somenoise][x].split('_')[-2]))\n",
    "    evolution_game = np.asarray(data[agent][exploration_strategy][somegrid][somebar][somenoise][somebar][somenoise][\"tables\"])[idxs]\n",
    "    idxs_o = sorted(range(len(name[agent][exploration_strategy][somegrid][someotherbar][someothernoise][someotherbar][someothernoise])), key=lambda x: int(name[agent][exploration_strategy][somegrid][someotherbar][someothernoise][someotherbar][someothernoise][x].split('_')[-2]))\n",
    "    evolution_game_other = np.asarray(data[agent][exploration_strategy][somegrid][someotherbar][someothernoise][someotherbar][someothernoise][\"tables\"])[idxs_o]\n",
    "    action_pd_no_noise = pd.DataFrame(evolution_game[-1]).sort_index()\n",
    "    action_pd_noise = pd.DataFrame(evolution_game_other[-1]).sort_index()\n",
    "    all_columns = pd.merge(action_pd_no_noise.fillna(np.nan).astype(float), action_pd_noise.fillna(np.nan).astype(float), how=\"outer\").columns\n",
    "    action_pd_no_noise_complete = pd.concat([action_pd_no_noise,pd.DataFrame(columns=list(set(all_columns) - set(action_pd_no_noise.columns)))]).fillna(np.nan).sort_index()[all_columns]\n",
    "    action_pd_noise_complete = pd.concat([action_pd_noise,pd.DataFrame(columns=list(set(all_columns) - set(action_pd_noise.columns)))]).fillna(np.nan).sort_index()[all_columns]\n",
    "    common_nan_mask = np.isnan(action_pd_no_noise_complete.values) & np.isnan(action_pd_noise_complete.values)\n",
    "    column_mask = np.all(common_nan_mask, axis=0)\n",
    "    masked_data_terminal = np.ma.masked_array(common_nan_mask, mask=np.repeat(column_mask.reshape(1,-1), 3, axis=0))\n",
    "    \n",
    "    #for sortex_idx in range(len(data[agent][exploration_strategy][somegrid][somebar][somenoise][somebar][somenoise][\"values\"])):\n",
    "    #fig, ax = plt.subplots(1,1, figsize=(27,27))\n",
    "    action_pd_no_noise = pd.DataFrame(evolution_game[sortex_idx]).sort_index()\n",
    "    action_pd_noise = pd.DataFrame(evolution_game_other[sortex_idx]).sort_index()\n",
    "\n",
    "    action_pd_no_noise_complete = pd.concat([action_pd_no_noise,pd.DataFrame(columns=list(set(all_columns) - set(action_pd_no_noise.columns)))]).fillna(np.nan).sort_index()[all_columns]\n",
    "    action_pd_noise_complete = pd.concat([action_pd_noise,pd.DataFrame(columns=list(set(all_columns) - set(action_pd_noise.columns)))]).fillna(np.nan).sort_index()[all_columns]\n",
    "    common_nan_mask = np.isnan(action_pd_no_noise_complete.values) & np.isnan(action_pd_noise_complete.values)\n",
    "    action_pd_noise_nan_mask = np.isnan(action_pd_noise_complete.values) & ~np.isnan(action_pd_no_noise_complete.values)\n",
    "    action_pd_no_noise_nan_mask = np.isnan(action_pd_no_noise_complete.values) & ~np.isnan(action_pd_noise_complete.values)\n",
    "\n",
    "    merge = pd.merge(action_pd_no_noise_complete, action_pd_noise_complete, how='outer')[all_columns]\n",
    "    a = abs(merge.iloc[:3,:].to_numpy() - merge.iloc[3:,:].to_numpy())\n",
    "    \n",
    "    if np.any(action_pd_noise_nan_mask == True):\n",
    "        reds = np.sum(action_pd_noise_nan_mask)\n",
    "    if np.any(action_pd_no_noise_nan_mask == True):\n",
    "        blues = np.sum(action_pd_no_noise_nan_mask)\n",
    "    greens = np.sum(masked_data_terminal.mask)\n",
    "    states = np.sum(~common_nan_mask) - reds - blues\n",
    "    G = data[agent][exploration_strategy][somegrid][somebar][somenoise][someotherbar][someothernoise][\"values\"][sortex_idx]\n",
    "    L = data[agent][exploration_strategy][somegrid][someotherbar][someothernoise][someotherbar][someothernoise][\"values\"][sortex_idx]\n",
    "    \n",
    "    return [reds, blues, states]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nanargmax_with_default(series):\n",
    "    return 0 if series.isna().all() else np.nanargmax(series)\n",
    "\n",
    "def generate_inner_explored_states(folder, subfolder, agent, exploration_strategy, somegrid, somebar, somenoise, someotherbar, someothernoise, sortex_idx):\n",
    "    \n",
    "    states_distribution = {}\n",
    "    if agent not in states_distribution:\n",
    "        states_distribution[agent] = {}\n",
    "    if exploration_strategy not in states_distribution[agent]:\n",
    "        states_distribution[agent][exploration_strategy] = {}\n",
    "    if somegrid not in states_distribution[agent][exploration_strategy]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid] = {}\n",
    "    if somebar not in states_distribution[agent][exploration_strategy][somegrid]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid][somebar] = {}\n",
    "    if somenoise not in states_distribution[agent][exploration_strategy][somegrid][somebar]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid][somebar][somenoise] = {}\n",
    "    if someotherbar not in states_distribution[agent][exploration_strategy][somegrid][somebar][somenoise]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid][somebar][somenoise][someotherbar] = {}\n",
    "    if someothernoise not in states_distribution[agent][exploration_strategy][somegrid][somebar][somenoise][someotherbar]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid][somebar][somenoise][someotherbar][someothernoise] = {}\n",
    "        \n",
    "    idxs = sorted(range(len(name[agent][exploration_strategy][somegrid][somebar][somenoise][somebar][somenoise])), key=lambda x: int(name[agent][exploration_strategy][somegrid][somebar][somenoise][somebar][somenoise][x].split('_')[-2]))\n",
    "    evolution_game = np.asarray(data[agent][exploration_strategy][somegrid][somebar][somenoise][somebar][somenoise][\"tables\"])[idxs]\n",
    "    idxs_o = sorted(range(len(name[agent][exploration_strategy][somegrid][someotherbar][someothernoise][someotherbar][someothernoise])), key=lambda x: int(name[agent][exploration_strategy][somegrid][someotherbar][someothernoise][someotherbar][someothernoise][x].split('_')[-2]))\n",
    "    evolution_game_other = np.asarray(data[agent][exploration_strategy][somegrid][someotherbar][someothernoise][someotherbar][someothernoise][\"tables\"])[idxs_o]\n",
    "\n",
    "    action_pd_no_noise = pd.DataFrame(evolution_game[-1]).sort_index()\n",
    "    action_pd_noise = pd.DataFrame(evolution_game_other[-1]).sort_index()\n",
    "    all_columns = action_pd_noise.columns.intersection(action_pd_no_noise.columns)\n",
    "    merge_common = pd.concat([action_pd_noise[all_columns], action_pd_no_noise[all_columns]], axis=0, keys=['action_pd_no_noise', 'action_pd_noise'])[all_columns]\n",
    "    merge_common.index = merge_common.index.droplevel()\n",
    "    final_column = np.argsort(merge_common.iloc[:3,:].apply(nanargmax_with_default).to_numpy() == merge_common.iloc[3:,:].apply(nanargmax_with_default).to_numpy())[::-1]\n",
    "    common_nan_mask = np.isnan(merge_common.iloc[:3,:].values) & np.isnan(merge_common.iloc[3:,:].values)\n",
    "    column_mask = np.all(common_nan_mask, axis=0)[final_column]\n",
    "    masked_data_terminal = np.ma.masked_array(common_nan_mask, mask=np.repeat(column_mask.reshape(1,-1), 3, axis=0))\n",
    "    all_columns = all_columns[final_column]\n",
    "    directory_path = f\"{folder}/{subfolder}\"\n",
    "\n",
    "    #for sortex_idx in range(len(data[agent][exploration_strategy][somegrid][somebar][somenoise][somebar][somenoise][\"values\"])):\n",
    "\n",
    "    action_pd_no_noise = pd.DataFrame(evolution_game[sortex_idx]).sort_index()\n",
    "    action_pd_noise = pd.DataFrame(evolution_game_other[sortex_idx]).sort_index()\n",
    "\n",
    "    common_columns = action_pd_no_noise.columns.intersection(action_pd_noise.columns)\n",
    "    action_pd_no_noise_common = pd.concat([action_pd_no_noise[common_columns],pd.DataFrame(columns=list(set(all_columns) - set(common_columns)))]).fillna(np.nan).sort_index()[all_columns]\n",
    "    action_pd_noise_common = pd.concat([action_pd_noise[common_columns],pd.DataFrame(columns=list(set(all_columns) - set(common_columns)))]).fillna(np.nan).sort_index()[all_columns]\n",
    "\n",
    "    merge_common = pd.concat([action_pd_no_noise_common, action_pd_noise_common], axis=0, keys=['action_pd_no_noise', 'action_pd_noise'])[all_columns]\n",
    "    a = pd.DataFrame(merge_common.iloc[:3,:].apply(nanargmax_with_default).to_numpy() == merge_common.iloc[3:,:].apply(nanargmax_with_default).to_numpy(), index=all_columns).values.astype(float)\n",
    "    states = a.shape[0]\n",
    "    common = states - np.sum(a)\n",
    "    perc_common = common/states\n",
    "    G = data[agent][exploration_strategy][somegrid][somebar][somenoise][someotherbar][someothernoise][\"values\"][sortex_idx]\n",
    "    L = data[agent][exploration_strategy][somegrid][someotherbar][someothernoise][someotherbar][someothernoise][\"values\"][sortex_idx]\n",
    "    states_distribution[agent][exploration_strategy][somegrid][somebar][somenoise][someotherbar][someothernoise][sortex_idx] = [perc_common, L, G]     \n",
    "    return [perc_common, L, G]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# SEMANTIC NOISE\n",
    "somegrid_l = ['pong-thick','pong']\n",
    "someagent_l = ['BoltzmannAgent','SarsaAgent']\n",
    "someexploration_strategy_l = ['Boltzmann','Egreedy']\n",
    "#training env\n",
    "somebar_l = ['ComputerBar_{\"index\":1,\"prob\":{}}','DirectionalComputerBar_{\"index\":1,\"prob\":0.3}','DirectionalComputerBar_{\"index\":1,\"prob\":0.6}'] \n",
    "somenoise_l = ['{\"mean\":0,\"std\":0}','{\"mean\":0,\"std\":0}','{\"mean\":0,\"std\":0}']\n",
    "#testing env\n",
    "someotherbar_l = ['ComputerBar_{\"index\":1,\"prob\":{}}','DirectionalComputerBar_{\"index\":1,\"prob\":0.3}','DirectionalComputerBar_{\"index\":1,\"prob\":0.6}']\n",
    "someothernoise_l = ['{\"mean\":0,\"std\":0.1}','{\"mean\":0,\"std\":0.1}','{\"mean\":0,\"std\":0.1}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_trial_learnability_BoltzmannAgent_Boltzmann_pong-thick_ComputerBar_{\"index\":1,\"prob\":{}}_{\"mean\":0,\"std\":0}\n",
      "_trial_learnability_BoltzmannAgent_Boltzmann_pong-thick_DirectionalComputerBar_{\"index\":1,\"prob\":0.3}_{\"mean\":0,\"std\":0}\n",
      "_trial_learnability_BoltzmannAgent_Boltzmann_pong-thick_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0}\n",
      "_trial_learnability_BoltzmannAgent_Boltzmann_pong_ComputerBar_{\"index\":1,\"prob\":{}}_{\"mean\":0,\"std\":0}\n",
      "_trial_learnability_BoltzmannAgent_Boltzmann_pong_DirectionalComputerBar_{\"index\":1,\"prob\":0.3}_{\"mean\":0,\"std\":0}\n",
      "_trial_learnability_BoltzmannAgent_Boltzmann_pong_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0}\n",
      "_trial_learnability_BoltzmannAgent_Boltzmann_pong-thick_ComputerBar_{\"index\":1,\"prob\":{}}_{\"mean\":0,\"std\":0}\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '_trial_learnability_BoltzmannAgent_Boltzmann_pong-thick_ComputerBar_{\"index\":1,\"prob\":{}}_{\"mean\":0,\"std\":0}/union_pong-thick_ComputerBar_{\"index\":1,\"prob\":{}}_{\"mean\":0,\"std\":0}_ComputerBar_{\"index\":1,\"prob\":{}}_{\"mean\":0,\"std\":0.1}.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[220], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m pickle_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m values \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 22\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpickle_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sortex_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data[agent][exploration_strategy][somegrid][somebar][somenoise][somebar][somenoise][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]))[:\u001b[38;5;241m2\u001b[39m]:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '_trial_learnability_BoltzmannAgent_Boltzmann_pong-thick_ComputerBar_{\"index\":1,\"prob\":{}}_{\"mean\":0,\"std\":0}/union_pong-thick_ComputerBar_{\"index\":1,\"prob\":{}}_{\"mean\":0,\"std\":0}_ComputerBar_{\"index\":1,\"prob\":{}}_{\"mean\":0,\"std\":0.1}.pkl'"
     ]
    }
   ],
   "source": [
    "for someagent in someagent_l:\n",
    "    if someagent not in name:\n",
    "        continue\n",
    "    for someexploration_strategy in someexploration_strategy_l:\n",
    "        if someexploration_strategy not in name[someagent]:\n",
    "            continue\n",
    "        for somegrid in somegrid_l:\n",
    "            if somegrid not in name[someagent][someexploration_strategy]:\n",
    "                continue\n",
    "            for somebar, somenoise, someotherbar, someothernoise in zip(somebar_l, somenoise_l, someotherbar_l, someothernoise_l):\n",
    "                if somebar not in name[someagent][someexploration_strategy][somegrid]:\n",
    "                    continue\n",
    "                if somenoise not in name[someagent][someexploration_strategy][somegrid][somebar]:\n",
    "                    continue\n",
    "                input_string = np.asarray(name[agent][exploration_strategy][somegrid][somebar][somenoise][somebar][somenoise])[0]\n",
    "                folder = re.sub(r\"_training_agent_\\d+_epoch\", \"\", input_string)\n",
    "                subfolder = f\"results_{somegrid}_{somebar}_{somenoise}_{someotherbar}_{someothernoise}\"\n",
    "                output_name = re.sub(\"results_\",\"\",subfolder)\n",
    "                pickle_file_path = f\"{folder}/{subfolder}.pkl\"\n",
    "                values = []\n",
    "                for sortex_idx in range(len(data[agent][exploration_strategy][somegrid][somebar][somenoise][somebar][somenoise][\"values\"]))\n",
    "                    a = generate_inner_explored_states(folder,subfolder,someagent, someexploration_strategy, somegrid, somebar, somenoise, someotherbar, someothernoise, sortex_idx)\n",
    "                    b = generate_occupancy(folder,subfolder,agent, exploration_strategy,somegrid, somebar, somenoise, someotherbar, someothernoise, sortex_idx)\n",
    "                    values.append(b + a)\n",
    "                with open(pickle_file_path, 'wb') as file:\n",
    "                    pickle.dump(values, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "def test_significance(x,y):\n",
    "    return scipy.stats.wilcoxon(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import csv \n",
    "\n",
    "data = {}\n",
    "name = {}\n",
    "paths = glob.glob(f'_trial_learnability*')\n",
    "\n",
    "for path in paths:\n",
    "    agent = path.split(\"_\")[-6]\n",
    "    exploration_strategy = path.split(\"_\")[-5]\n",
    "    pkl_files = glob.glob(os.path.join(path, 'results*.pkl'))\n",
    "    for file in pkl_files:\n",
    "        path_file = file.split(\"/\")[1]\n",
    "        grid = path_file.split(\"_\")[1]\n",
    "        bar = \"_\".join(path_file.split(\"_\")[2:4])\n",
    "        noise = \"\".join(path_file.split(\"_\")[4])\n",
    "        otherbar = \"_\".join(path_file.split(\"_\")[5:7])\n",
    "        othernoise = path_file.split(\"_\")[7].replace(\".pkl\",\"\")\n",
    "        if agent not in data:\n",
    "            data[agent] = {}\n",
    "        if exploration_strategy not in data[agent]:\n",
    "            data[agent][exploration_strategy] = {}\n",
    "        if grid not in data[agent][exploration_strategy]:\n",
    "            data[agent][exploration_strategy][grid] = {}\n",
    "        if bar not in data[agent][exploration_strategy][grid]:\n",
    "            data[agent][exploration_strategy][grid][bar] = {}\n",
    "        if noise not in data[agent][exploration_strategy][grid][bar]:\n",
    "            data[agent][exploration_strategy][grid][bar][noise] = {}\n",
    "        if otherbar not in data[agent][exploration_strategy][grid][bar][noise]:\n",
    "            data[agent][exploration_strategy][grid][bar][noise][otherbar] = {}\n",
    "        if othernoise not in data[agent][exploration_strategy][grid][bar][noise][otherbar]:\n",
    "            data[agent][exploration_strategy][grid][bar][noise][otherbar][othernoise] = []\n",
    "        with open(file, 'rb') as file:\n",
    "            values = pickle.load(file)\n",
    "        data[agent][exploration_strategy][grid][bar][noise][otherbar][othernoise] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_pong_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0}_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0.1}.pkl\n",
      "results_pong_ComputerBar_{\"index\":1,\"prob\":{}}_{\"mean\":0,\"std\":0}_ComputerBar_{\"index\":1,\"prob\":{}}_{\"mean\":0,\"std\":0.1}.pkl\n",
      "results_pong-thick_DirectionalComputerBar_{\"index\":1,\"prob\":0.3}_{\"mean\":0,\"std\":0}_DirectionalComputerBar_{\"index\":1,\"prob\":0.3}_{\"mean\":0,\"std\":0.1}.pkl\n",
      "results_pong-thick_DirectionalComputerBar_{\"index\":1,\"prob\":0.3}_{\"mean\":0,\"std\":0}_DirectionalComputerBar_{\"index\":1,\"prob\":0.3}_{\"mean\":0,\"std\":0.1}.pkl\n",
      "results_pong_DirectionalComputerBar_{\"index\":1,\"prob\":0.3}_{\"mean\":0,\"std\":0}_DirectionalComputerBar_{\"index\":1,\"prob\":0.3}_{\"mean\":0,\"std\":0.1}.pkl\n",
      "results_pong-thick_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0}_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0.1}.pkl\n",
      "results_pong-thick_DirectionalComputerBar_{\"index\":1,\"prob\":0.3}_{\"mean\":0,\"std\":0}_DirectionalComputerBar_{\"index\":1,\"prob\":0.3}_{\"mean\":0,\"std\":0.1}.pkl\n",
      "results_pong_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0}_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0.1}.pkl\n",
      "results_pong_DirectionalComputerBar_{\"index\":1,\"prob\":0.3}_{\"mean\":0,\"std\":0}_DirectionalComputerBar_{\"index\":1,\"prob\":0.3}_{\"mean\":0,\"std\":0.1}.pkl\n",
      "results_pong-thick_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0}_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0.1}.pkl\n",
      "results_pong_DirectionalComputerBar_{\"index\":1,\"prob\":0.3}_{\"mean\":0,\"std\":0}_DirectionalComputerBar_{\"index\":1,\"prob\":0.3}_{\"mean\":0,\"std\":0.1}.pkl\n",
      "results_pong_ComputerBar_{\"index\":1,\"prob\":{}}_{\"mean\":0,\"std\":0}_ComputerBar_{\"index\":1,\"prob\":{}}_{\"mean\":0,\"std\":0.1}.pkl\n",
      "results_pong_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0}_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0.1}.pkl\n",
      "results_pong-thick_ComputerBar_{\"index\":1,\"prob\":{}}_{\"mean\":0,\"std\":0}_ComputerBar_{\"index\":1,\"prob\":{}}_{\"mean\":0,\"std\":0.1}.pkl\n",
      "results_pong-thick_ComputerBar_{\"index\":1,\"prob\":{}}_{\"mean\":0,\"std\":0}_ComputerBar_{\"index\":1,\"prob\":{}}_{\"mean\":0,\"std\":0.1}.pkl\n",
      "results_pong_ComputerBar_{\"index\":1,\"prob\":{}}_{\"mean\":0,\"std\":0}_ComputerBar_{\"index\":1,\"prob\":{}}_{\"mean\":0,\"std\":0.1}.pkl\n",
      "results_pong-thick_ComputerBar_{\"index\":1,\"prob\":{}}_{\"mean\":0,\"std\":0}_ComputerBar_{\"index\":1,\"prob\":{}}_{\"mean\":0,\"std\":0.1}.pkl\n",
      "results_pong-thick_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0}_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0.1}.pkl\n",
      "results_pong-thick_DirectionalComputerBar_{\"index\":1,\"prob\":0.3}_{\"mean\":0,\"std\":0}_DirectionalComputerBar_{\"index\":1,\"prob\":0.3}_{\"mean\":0,\"std\":0.1}.pkl\n",
      "results_pong-thick_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0}_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0.1}.pkl\n",
      "results_pong_DirectionalComputerBar_{\"index\":1,\"prob\":0.3}_{\"mean\":0,\"std\":0}_DirectionalComputerBar_{\"index\":1,\"prob\":0.3}_{\"mean\":0,\"std\":0.1}.pkl\n",
      "results_pong_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0}_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0.1}.pkl\n",
      "results_pong-thick_ComputerBar_{\"index\":1,\"prob\":{}}_{\"mean\":0,\"std\":0}_ComputerBar_{\"index\":1,\"prob\":{}}_{\"mean\":0,\"std\":0.1}.pkl\n",
      "results_pong_ComputerBar_{\"index\":1,\"prob\":{}}_{\"mean\":0,\"std\":0}_ComputerBar_{\"index\":1,\"prob\":{}}_{\"mean\":0,\"std\":0.1}.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import csv \n",
    "\n",
    "\n",
    "contents_lg = {}\n",
    "contents_lg['blue'] = []\n",
    "contents_lg['red'] = []\n",
    "contents_lg['states'] = []\n",
    "contents_lg['perc_common'] = []\n",
    "gap_lg = []\n",
    "\n",
    "a = {'pong':[], 'pong-thick':[]}\n",
    "for path in paths:\n",
    "    agent = path.split(\"_\")[-6]\n",
    "    exploration_strategy = path.split(\"_\")[-5]\n",
    "    pkl_files = glob.glob(os.path.join(path, 'results*.pkl'))\n",
    "    for file in pkl_files:\n",
    "        path_file = file.split(\"/\")[1]\n",
    "        print(path_file)\n",
    "        grid = path_file.split(\"_\")[1]\n",
    "        \n",
    "        with open(file, 'rb') as file:\n",
    "            values = pickle.load(file)\n",
    "        for value in values[-1:]:\n",
    "            a[grid].append(value[1]/value[2])\n",
    "            contents_lg['red'].append(value[0]/value[2])\n",
    "            contents_lg['blue'].append(value[1]/value[2])\n",
    "            contents_lg['states'].append(value[2])\n",
    "            contents_lg['perc_common'].append(value[3])\n",
    "    \n",
    "            gap_lg.append(value[5] - value[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(contents_lg['blue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'tuple' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[321], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39mmean(a[\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgap_lg\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m]), np\u001b[38;5;241m.\u001b[39mmean(a[np\u001b[38;5;241m.\u001b[39mwhere(gap_lg)\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;66;03m#scipy.stats.ttest_ind(a['pong'],a['pong-thick'])\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'tuple' and 'int'"
     ]
    }
   ],
   "source": [
    "np.mean(a[np.where(gap_lg)>0]), np.mean(a[np.where(gap_lg)<0]) #scipy.stats.ttest_ind(a['pong'],a['pong-thick'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WilcoxonResult(statistic=0.0, pvalue=1.1920928955078125e-07),\n",
       " WilcoxonResult(statistic=6.0, pvalue=1.6689300537109375e-06),\n",
       " WilcoxonResult(statistic=142.0, pvalue=0.8333734273910522),\n",
       " WilcoxonResult(statistic=0.0, pvalue=1.1920928955078125e-07))"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_significance(contents_lg['perc_common'], contents_lg['blue']), test_significance(gap_lg, contents_lg['red']), test_significance(gap_lg, contents_lg['states']), test_significance(gap_lg, contents_lg['perc_common'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = pd.DataFrame({\"gap_lg\":gap_lg,\"blue\":contents_lg['blue'], \"red\":contents_lg['red'], \"states\":contents_lg['states'], \"perc_common\":contents_lg['perc_common']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics.sort_values(by='gap_lg', ascending=True).to_csv(\"stats.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
