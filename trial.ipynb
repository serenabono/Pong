{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import plotly\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "import plotly.express as px\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_trial_learnability_BoltzmannAgent_Boltzmann_pong_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0.5}', '_trial_learnability_BoltzmannAgent_Boltzmann_pong_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0.1}', '_trial_generalization_BoltzmannAgent_Boltzmann_pong_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0}', '_trial_learnability_BoltzmannAgent_Boltzmann_pong_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0}']\n",
      "_trial_learnability_BoltzmannAgent_Boltzmann_pong_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0.5}\n",
      "_trial_learnability_BoltzmannAgent_Boltzmann_pong_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0.1}\n",
      "_trial_generalization_BoltzmannAgent_Boltzmann_pong_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0}\n",
      "_trial_learnability_BoltzmannAgent_Boltzmann_pong_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}_{\"mean\":0,\"std\":0}\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 56\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m csvfile:\n\u001b[1;32m     55\u001b[0m     reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(csvfile, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m reader:\n\u001b[1;32m     57\u001b[0m         values\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(row[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m     58\u001b[0m data[agent][exploration_strategy][grid][bar][noise][otherbar][othernoise][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m values\n",
      "File \u001b[0;32m~/miniconda3/envs/.py39env/lib/python3.9/codecs.py:322\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m--> 322\u001b[0m     (result, consumed) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;66;03m# keep undecoded input until the next call\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m=\u001b[39m data[consumed:]\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import csv \n",
    "\n",
    "data = {}\n",
    "name = {}\n",
    "filename = 'BoltzmannAgent_Boltzmann_pong_DirectionalComputerBar_{\"index\":1,\"prob\":0.6}'\n",
    "paths = glob.glob(f'_trial_*{filename}*')\n",
    "print(paths)\n",
    "for path in paths:\n",
    "    print(path)\n",
    "    agent = path.split(\"_\")[-6]\n",
    "    exploration_strategy = path.split(\"_\")[-5]\n",
    "    grid = path.split(\"_\")[-4]\n",
    "    bar = \"_\".join(path.split(\"_\")[-3:-1])\n",
    "    noise = \"\".join(path.split(\"_\")[-1])\n",
    "    pkl_files = glob.glob(os.path.join(path, '*.pkl'))\n",
    "    for file in pkl_files:        \n",
    "        if \"learnability\" in path:\n",
    "            otherbar = bar\n",
    "            othernoise = noise\n",
    "        else:\n",
    "            repeat_grid = file.split(\"_\")[3]\n",
    "            path_file = f\"_{repeat_grid}\" + re.findall(r'-test.*?_end', file)[0]\n",
    "            path_file = path_file.replace(\"'\",\"\\\"\").replace(\" \", \"\").replace(\"-train\",\"\").replace(\"-test\",\"\").replace(\"_end\", \"\")\n",
    "            otherbar = \"_\".join(path_file.split(\"_\")[2:4])\n",
    "            othernoise = path_file.split(\"_\")[4]\n",
    "            \n",
    "        if agent not in data:\n",
    "            data[agent] = {}\n",
    "            name[agent] = {}\n",
    "        if exploration_strategy not in data[agent]:\n",
    "            data[agent][exploration_strategy] = {}\n",
    "            name[agent][exploration_strategy] = {}\n",
    "        if grid not in data[agent][exploration_strategy]:\n",
    "            data[agent][exploration_strategy][grid] = {}\n",
    "            name[agent][exploration_strategy][grid] = {}\n",
    "        if bar not in data[agent][exploration_strategy][grid]:\n",
    "            data[agent][exploration_strategy][grid][bar] = {}\n",
    "            name[agent][exploration_strategy][grid][bar] = {}\n",
    "        if noise not in data[agent][exploration_strategy][grid][bar]:\n",
    "            data[agent][exploration_strategy][grid][bar][noise] = {}\n",
    "            name[agent][exploration_strategy][grid][bar][noise] = {}\n",
    "        if otherbar not in data[agent][exploration_strategy][grid][bar][noise]:\n",
    "            data[agent][exploration_strategy][grid][bar][noise][otherbar] = {}\n",
    "            name[agent][exploration_strategy][grid][bar][noise][otherbar] = {}\n",
    "        if othernoise not in data[agent][exploration_strategy][grid][bar][noise][otherbar]:\n",
    "            name[agent][exploration_strategy][grid][bar][noise][otherbar][othernoise] = []\n",
    "            data[agent][exploration_strategy][grid][bar][noise][otherbar][othernoise] = {}\n",
    "            data[agent][exploration_strategy][grid][bar][noise][otherbar][othernoise][\"tables\"] = []\n",
    "    \n",
    "        values = []\n",
    "        with open(file, newline='') as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter='\\n', quotechar='|')\n",
    "            for row in reader:\n",
    "                values.append(float(row[0]))\n",
    "        data[agent][exploration_strategy][grid][bar][noise][otherbar][othernoise][\"values\"] = values\n",
    "    \n",
    "        json_files = glob.glob(os.path.join(path, '*.json'))\n",
    "        \n",
    "        for file in json_files:\n",
    "            with open(file) as f:\n",
    "                train_epoch = file.split(\"-\")[-1].replace(rf\"train0_\",\"\").replace(\".json\",\"\")\n",
    "                data[agent][exploration_strategy][grid][bar][noise][otherbar][othernoise][\"tables\"].append(json.load(f))\n",
    "                name[agent][exploration_strategy][grid][bar][noise][otherbar][othernoise].append(f'{re.sub(\"./_trial_\", \"\", path)}_{train_epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import imageio\n",
    "\n",
    "def generate_occupancy(folder,subfolder,agent, exploration_strategy, somegrid, somebar, somenoise, someotherbar, someothernoise, sortex_idx):\n",
    "    \n",
    "    states_distribution = {}\n",
    "    if agent not in states_distribution:\n",
    "        states_distribution[agent] = {}\n",
    "    if exploration_strategy not in states_distribution[agent]:\n",
    "        states_distribution[agent][exploration_strategy] = {}\n",
    "    if somegrid not in states_distribution[agent][exploration_strategy]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid] = {}\n",
    "    if somebar not in states_distribution[agent][exploration_strategy][somegrid]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid][somebar] = {}\n",
    "    if somenoise not in states_distribution[agent][exploration_strategy][somegrid][somebar]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid][somebar][somenoise] = {}\n",
    "    if someotherbar not in states_distribution[agent][exploration_strategy][somegrid][somebar][somenoise]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid][somebar][somenoise][someotherbar] = {}\n",
    "    if someothernoise not in states_distribution[agent][exploration_strategy][somegrid][somebar][somenoise][someotherbar]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid][somebar][somenoise][someotherbar][someothernoise] = {}\n",
    "        \n",
    "    idxs = sorted(range(len(name[agent][exploration_strategy][somegrid][somebar][somenoise][somebar][somenoise])), key=lambda x: int(name[agent][exploration_strategy][somegrid][somebar][somenoise][somebar][somenoise][x].split('_')[-2]))\n",
    "    evolution_game = np.asarray(data[agent][exploration_strategy][somegrid][somebar][somenoise][somebar][somenoise][\"tables\"])[idxs]\n",
    "    idxs_o = sorted(range(len(name[agent][exploration_strategy][somegrid][someotherbar][someothernoise][someotherbar][someothernoise])), key=lambda x: int(name[agent][exploration_strategy][somegrid][someotherbar][someothernoise][someotherbar][someothernoise][x].split('_')[-2]))\n",
    "    evolution_game_other = np.asarray(data[agent][exploration_strategy][somegrid][someotherbar][someothernoise][someotherbar][someothernoise][\"tables\"])[idxs_o]\n",
    "    action_pd_no_noise = pd.DataFrame(evolution_game[-1]).sort_index()\n",
    "    action_pd_noise = pd.DataFrame(evolution_game_other[-1]).sort_index()\n",
    "    all_columns = pd.merge(action_pd_no_noise.fillna(np.nan).astype(float), action_pd_noise.fillna(np.nan).astype(float), how=\"outer\").columns\n",
    "    action_pd_no_noise_complete = pd.concat([action_pd_no_noise,pd.DataFrame(columns=list(set(all_columns) - set(action_pd_no_noise.columns)))]).fillna(np.nan).sort_index()[all_columns]\n",
    "    action_pd_noise_complete = pd.concat([action_pd_noise,pd.DataFrame(columns=list(set(all_columns) - set(action_pd_noise.columns)))]).fillna(np.nan).sort_index()[all_columns]\n",
    "    common_nan_mask = np.isnan(action_pd_no_noise_complete.values) & np.isnan(action_pd_noise_complete.values)\n",
    "    column_mask = np.all(common_nan_mask, axis=0)\n",
    "    masked_data_terminal = np.ma.masked_array(common_nan_mask, mask=np.repeat(column_mask.reshape(1,-1), 3, axis=0))\n",
    "    \n",
    "    #for sortex_idx in range(len(data[agent][exploration_strategy][somegrid][somebar][somenoise][somebar][somenoise][\"values\"])):\n",
    "    #fig, ax = plt.subplots(1,1, figsize=(27,27))\n",
    "    action_pd_no_noise = pd.DataFrame(evolution_game[sortex_idx]).sort_index()\n",
    "    action_pd_noise = pd.DataFrame(evolution_game_other[sortex_idx]).sort_index()\n",
    "\n",
    "    action_pd_no_noise_complete = pd.concat([action_pd_no_noise,pd.DataFrame(columns=list(set(all_columns) - set(action_pd_no_noise.columns)))]).fillna(np.nan).sort_index()[all_columns]\n",
    "    action_pd_noise_complete = pd.concat([action_pd_noise,pd.DataFrame(columns=list(set(all_columns) - set(action_pd_noise.columns)))]).fillna(np.nan).sort_index()[all_columns]\n",
    "    common_nan_mask = np.isnan(action_pd_no_noise_complete.values) & np.isnan(action_pd_noise_complete.values)\n",
    "    action_pd_noise_nan_mask = np.isnan(action_pd_noise_complete.values) & ~np.isnan(action_pd_no_noise_complete.values)\n",
    "    action_pd_no_noise_nan_mask = np.isnan(action_pd_no_noise_complete.values) & ~np.isnan(action_pd_noise_complete.values)\n",
    "\n",
    "    merge = pd.merge(action_pd_no_noise_complete, action_pd_noise_complete, how='outer')[all_columns]\n",
    "    a = abs(merge.iloc[:3,:].to_numpy() - merge.iloc[3:,:].to_numpy())\n",
    "    \n",
    "    if np.any(action_pd_noise_nan_mask == True):\n",
    "        reds = np.sum(action_pd_noise_nan_mask)\n",
    "    if np.any(action_pd_no_noise_nan_mask == True):\n",
    "        blues = np.sum(action_pd_no_noise_nan_mask)\n",
    "    greens = np.sum(masked_data_terminal.mask)\n",
    "    states = np.sum(~common_nan_mask) - reds - blues\n",
    "    G = data[agent][exploration_strategy][somegrid][somebar][somenoise][someotherbar][someothernoise][\"values\"][sortex_idx]\n",
    "    L = data[agent][exploration_strategy][somegrid][someotherbar][someothernoise][someotherbar][someothernoise][\"values\"][sortex_idx]\n",
    "    \n",
    "    return [reds, blues, states]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nanargmax_with_default(series):\n",
    "    return 0 if series.isna().all() else np.nanargmax(series)\n",
    "\n",
    "def generate_inner_explored_states(folder, subfolder, agent, exploration_strategy, somegrid, somebar, somenoise, someotherbar, someothernoise, sortex_idx):\n",
    "    \n",
    "    states_distribution = {}\n",
    "    if agent not in states_distribution:\n",
    "        states_distribution[agent] = {}\n",
    "    if exploration_strategy not in states_distribution[agent]:\n",
    "        states_distribution[agent][exploration_strategy] = {}\n",
    "    if somegrid not in states_distribution[agent][exploration_strategy]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid] = {}\n",
    "    if somebar not in states_distribution[agent][exploration_strategy][somegrid]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid][somebar] = {}\n",
    "    if somenoise not in states_distribution[agent][exploration_strategy][somegrid][somebar]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid][somebar][somenoise] = {}\n",
    "    if someotherbar not in states_distribution[agent][exploration_strategy][somegrid][somebar][somenoise]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid][somebar][somenoise][someotherbar] = {}\n",
    "    if someothernoise not in states_distribution[agent][exploration_strategy][somegrid][somebar][somenoise][someotherbar]:\n",
    "        states_distribution[agent][exploration_strategy][somegrid][somebar][somenoise][someotherbar][someothernoise] = {}\n",
    "        \n",
    "    idxs = sorted(range(len(name[agent][exploration_strategy][somegrid][somebar][somenoise][somebar][somenoise])), key=lambda x: int(name[agent][exploration_strategy][somegrid][somebar][somenoise][somebar][somenoise][x].split('_')[-2]))\n",
    "    evolution_game = np.asarray(data[agent][exploration_strategy][somegrid][somebar][somenoise][somebar][somenoise][\"tables\"])[idxs]\n",
    "    idxs_o = sorted(range(len(name[agent][exploration_strategy][somegrid][someotherbar][someothernoise][someotherbar][someothernoise])), key=lambda x: int(name[agent][exploration_strategy][somegrid][someotherbar][someothernoise][someotherbar][someothernoise][x].split('_')[-2]))\n",
    "    evolution_game_other = np.asarray(data[agent][exploration_strategy][somegrid][someotherbar][someothernoise][someotherbar][someothernoise][\"tables\"])[idxs_o]\n",
    "\n",
    "    action_pd_no_noise = pd.DataFrame(evolution_game[-1]).sort_index()\n",
    "    action_pd_noise = pd.DataFrame(evolution_game_other[-1]).sort_index()\n",
    "    all_columns = action_pd_noise.columns.intersection(action_pd_no_noise.columns)\n",
    "    merge_common = pd.concat([action_pd_noise[all_columns], action_pd_no_noise[all_columns]], axis=0, keys=['action_pd_no_noise', 'action_pd_noise'])[all_columns]\n",
    "    merge_common.index = merge_common.index.droplevel()\n",
    "    final_column = np.argsort(merge_common.iloc[:3,:].apply(nanargmax_with_default).to_numpy() == merge_common.iloc[3:,:].apply(nanargmax_with_default).to_numpy())[::-1]\n",
    "    common_nan_mask = np.isnan(merge_common.iloc[:3,:].values) & np.isnan(merge_common.iloc[3:,:].values)\n",
    "    column_mask = np.all(common_nan_mask, axis=0)[final_column]\n",
    "    masked_data_terminal = np.ma.masked_array(common_nan_mask, mask=np.repeat(column_mask.reshape(1,-1), 3, axis=0))\n",
    "    all_columns = all_columns[final_column]\n",
    "    directory_path = f\"{folder}/{subfolder}\"\n",
    "\n",
    "    #for sortex_idx in range(len(data[agent][exploration_strategy][somegrid][somebar][somenoise][somebar][somenoise][\"values\"])):\n",
    "\n",
    "    action_pd_no_noise = pd.DataFrame(evolution_game[sortex_idx]).sort_index()\n",
    "    action_pd_noise = pd.DataFrame(evolution_game_other[sortex_idx]).sort_index()\n",
    "\n",
    "    common_columns = action_pd_no_noise.columns.intersection(action_pd_noise.columns)\n",
    "    action_pd_no_noise_common = pd.concat([action_pd_no_noise[common_columns],pd.DataFrame(columns=list(set(all_columns) - set(common_columns)))]).fillna(np.nan).sort_index()[all_columns]\n",
    "    action_pd_noise_common = pd.concat([action_pd_noise[common_columns],pd.DataFrame(columns=list(set(all_columns) - set(common_columns)))]).fillna(np.nan).sort_index()[all_columns]\n",
    "\n",
    "    merge_common = pd.concat([action_pd_no_noise_common, action_pd_noise_common], axis=0, keys=['action_pd_no_noise', 'action_pd_noise'])[all_columns]\n",
    "    a = pd.DataFrame(merge_common.iloc[:3,:].apply(nanargmax_with_default).to_numpy() == merge_common.iloc[3:,:].apply(nanargmax_with_default).to_numpy(), index=all_columns).values.astype(float)\n",
    "    states = a.shape[0]\n",
    "    common = states - np.sum(a)\n",
    "    perc_common = common/states\n",
    "    G = data[agent][exploration_strategy][somegrid][somebar][somenoise][someotherbar][someothernoise][\"values\"][sortex_idx]\n",
    "    L = data[agent][exploration_strategy][somegrid][someotherbar][someothernoise][someotherbar][someothernoise][\"values\"][sortex_idx]\n",
    "    states_distribution[agent][exploration_strategy][somegrid][somebar][somenoise][someotherbar][someothernoise][sortex_idx] = [perc_common, L, G]     \n",
    "    return [perc_common, L, G]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# SEMANTIC NOISE\n",
    "somegrid_l = ['pong-thick','pong']\n",
    "someagent_l = ['BoltzmannAgent','SarsaAgent']\n",
    "someexploration_strategy_l = ['Boltzmann','Egreedy']\n",
    "#training env\n",
    "somebar_l = ['ComputerBar_{\"index\":1,\"prob\":{}}','DirectionalComputerBar_{\"index\":1,\"prob\":0.3}','DirectionalComputerBar_{\"index\":1,\"prob\":0.6}'] \n",
    "somenoise_l = ['{\"mean\":0,\"std\":0}','{\"mean\":0,\"std\":0}','{\"mean\":0,\"std\":0}']\n",
    "#testing env\n",
    "someotherbar_l = ['ComputerBar_{\"index\":1,\"prob\":{}}','DirectionalComputerBar_{\"index\":1,\"prob\":0.3}','DirectionalComputerBar_{\"index\":1,\"prob\":0.6}']\n",
    "someothernoise_l = ['{\"mean\":0,\"std\":0.1}','{\"mean\":0,\"std\":0.1}','{\"mean\":0,\"std\":0.1}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for someagent in someagent_l:\n",
    "    if someagent not in name:\n",
    "        continue\n",
    "    for someexploration_strategy in someexploration_strategy_l:\n",
    "        if someexploration_strategy not in name[someagent]:\n",
    "            continue\n",
    "        for somegrid in somegrid_l:\n",
    "            if somegrid not in name[someagent][someexploration_strategy]:\n",
    "                continue\n",
    "            for somebar, somenoise, someotherbar, someothernoise in zip(somebar_l, somenoise_l, someotherbar_l, someothernoise_l):\n",
    "                if somebar not in name[someagent][someexploration_strategy][somegrid]:\n",
    "                    continue\n",
    "                if somenoise not in name[someagent][someexploration_strategy][somegrid][somebar]:\n",
    "                    continue\n",
    "                input_string = np.asarray(name[agent][exploration_strategy][somegrid][somebar][somenoise][somebar][somenoise])[0]\n",
    "                folder = re.sub(r\"_training_agent_\\d+_epoch\", \"\", input_string)\n",
    "                subfolder = f\"results_{somegrid}_{somebar}_{somenoise}_{someotherbar}_{someothernoise}\"\n",
    "                output_name = re.sub(\"results_\",\"\",subfolder)\n",
    "                pickle_file_path = f\"{folder}/{subfolder}.pkl\"\n",
    "                values = []\n",
    "                for sortex_idx in range(len(data[agent][exploration_strategy][somegrid][somebar][somenoise][somebar][somenoise][\"values\"]))\n",
    "                    a = generate_inner_explored_states(folder,subfolder,someagent, someexploration_strategy, somegrid, somebar, somenoise, someotherbar, someothernoise, sortex_idx)\n",
    "                    b = generate_occupancy(folder,subfolder,agent, exploration_strategy,somegrid, somebar, somenoise, someotherbar, someothernoise, sortex_idx)\n",
    "                    values.append(b + a)\n",
    "                with open(pickle_file_path, 'wb') as file:\n",
    "                    pickle.dump(values, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "def test_significance(x,y):\n",
    "    return scipy.stats.wilcoxon(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import csv \n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "data = {}\n",
    "name = {}\n",
    "paths = glob.glob(f'_trial_learnability*')\n",
    "\n",
    "for path in paths:\n",
    "    agent = path.split(\"_\")[-6]\n",
    "    exploration_strategy = path.split(\"_\")[-5]\n",
    "    pkl_files = glob.glob(os.path.join(path, 'results*.pkl'))\n",
    "    for file in pkl_files:\n",
    "        path_file = file.split(\"/\")[1]\n",
    "        grid = path_file.split(\"_\")[1]\n",
    "        bar = \"_\".join(path_file.split(\"_\")[2:4])\n",
    "        noise = \"\".join(path_file.split(\"_\")[4])\n",
    "        otherbar = \"_\".join(path_file.split(\"_\")[5:7])\n",
    "        othernoise = path_file.split(\"_\")[7].replace(\".pkl\",\"\")\n",
    "        if agent not in data:\n",
    "            data[agent] = {}\n",
    "        if exploration_strategy not in data[agent]:\n",
    "            data[agent][exploration_strategy] = {}\n",
    "        if grid not in data[agent][exploration_strategy]:\n",
    "            data[agent][exploration_strategy][grid] = {}\n",
    "        if bar not in data[agent][exploration_strategy][grid]:\n",
    "            data[agent][exploration_strategy][grid][bar] = {}\n",
    "        if noise not in data[agent][exploration_strategy][grid][bar]:\n",
    "            data[agent][exploration_strategy][grid][bar][noise] = {}\n",
    "        if otherbar not in data[agent][exploration_strategy][grid][bar][noise]:\n",
    "            data[agent][exploration_strategy][grid][bar][noise][otherbar] = {}\n",
    "        if othernoise not in data[agent][exploration_strategy][grid][bar][noise][otherbar]:\n",
    "            data[agent][exploration_strategy][grid][bar][noise][otherbar][othernoise] = []\n",
    "        with open(file, 'rb') as file:\n",
    "            values = pickle.load(file)\n",
    "        data[agent][exploration_strategy][grid][bar][noise][otherbar][othernoise] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import csv \n",
    "\n",
    "\n",
    "contents_lg = {}\n",
    "contents_lg['blue'] = []\n",
    "contents_lg['red'] = []\n",
    "contents_lg['states'] = []\n",
    "contents_lg['perc_common'] = []\n",
    "gap_lg = []\n",
    "\n",
    "a = {'pong':[], 'pong-thick':[]}\n",
    "for path in paths:\n",
    "    agent = path.split(\"_\")[-6]\n",
    "    exploration_strategy = path.split(\"_\")[-5]\n",
    "    pkl_files = glob.glob(os.path.join(path, 'results*.pkl'))\n",
    "    for file in pkl_files:\n",
    "        path_file = file.split(\"/\")[1]\n",
    "        grid = path_file.split(\"_\")[1]\n",
    "        \n",
    "        with open(file, 'rb') as file:\n",
    "            values = pickle.load(file)\n",
    "        for value in values[-10:]:\n",
    "            a[grid].append(value[1]/value[2])\n",
    "            contents_lg['red'].append(value[0]/value[2])\n",
    "            contents_lg['blue'].append(value[1]/value[2])\n",
    "            contents_lg['states'].append(value[2])\n",
    "            contents_lg['perc_common'].append(value[3])\n",
    "    \n",
    "            gap_lg.append((value[5] - value[4])/(value[5] + value[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TtestResult(statistic=-1.1844172087341307, pvalue=0.23742941004390467, df=238.0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array(contents_lg['blue'])\n",
    "scipy.stats.ttest_ind(a[np.where(np.array(gap_lg)>0)], a[np.where(np.array(gap_lg)<0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson's correlation coefficient: -0.0580512908823649\n",
      "Pearson's p-value: 0.37058033960302766\n",
      "Spearman's correlation coefficient: -0.17827767075834117\n",
      "Spearman's p-value: 0.005611331051792124\n"
     ]
    }
   ],
   "source": [
    "# Pearson's correlation test\n",
    "pearson_corr, pearson_p_value = scipy.stats.pearsonr(contents_lg['blue'], gap_lg)\n",
    "print(f\"Pearson's correlation coefficient: {pearson_corr}\")\n",
    "print(f\"Pearson's p-value: {pearson_p_value}\")\n",
    "\n",
    "# Spearman's correlation test\n",
    "spearman_corr, spearman_p_value = scipy.stats.spearmanr(contents_lg['blue'], gap_lg)\n",
    "print(f\"Spearman's correlation coefficient: {spearman_corr}\")\n",
    "print(f\"Spearman's p-value: {spearman_p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WilcoxonResult(statistic=226985.0, pvalue=1.2178625332656769e-28),\n",
       " WilcoxonResult(statistic=327596.0, pvalue=0.006456857891950339),\n",
       " WilcoxonResult(statistic=0.0, pvalue=8.134562720099235e-198),\n",
       " WilcoxonResult(statistic=75440.0, pvalue=2.062957754655048e-124))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_significance(gap_lg, contents_lg['blue']), test_significance(gap_lg, contents_lg['red']), test_significance(gap_lg, contents_lg['states']), test_significance(gap_lg, contents_lg['perc_common'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (2451677780.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[59], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    a['pong'],a['pong-thick'])\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "np.mean(gap_lg), np.mean(a['pong-thick'])\n",
    "a['pong'],a['pong-thick'])\n",
    "scipy.stats.ttest_ind(a['pong'],a['pong-thick'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = pd.DataFrame({\"gap_lg\":gap_lg,\"blue\":contents_lg['blue'], \"red\":contents_lg['red'], \"states\":contents_lg['states'], \"perc_common\":contents_lg['perc_common']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics.sort_values(by='gap_lg', ascending=True).to_csv(\"stats.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
